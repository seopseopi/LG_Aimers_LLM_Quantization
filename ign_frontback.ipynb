{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18cd4717",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from llmcompressor import oneshot\n",
    "from llmcompressor.modifiers.quantization import GPTQModifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b01058d",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61485104",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"./base_model\"     \n",
    "OUT_DIR  = \"./model\"          \n",
    "\n",
    "DATASET_ID = \"LGAI-EXAONE/MANTA-1M\"\n",
    "DATASET_SPLIT = \"train\"\n",
    "\n",
    "NUM_CALIBRATION_SAMPLES = 1024\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "\n",
    "# Quantization\n",
    "SCHEME = \"W4A16\"\n",
    "TARGETS = [\"Linear\"]\n",
    "\n",
    "skip_indices = list(range(0, 5))\n",
    "skip_layers0 = [f\"model.layers.{i}.self_attn.q_proj\" for i in skip_indices]\n",
    "skip_layers1 = [f\"model.layers.{i}.self_attn.k_proj\" for i in skip_indices]\n",
    "skip_layers2 = [f\"model.layers.{i}.self_attn.v_proj\" for i in skip_indices]\n",
    "skip_layers3 = [f\"model.layers.{i}.self_attn.o_proj\" for i in skip_indices]\n",
    "skip_layers4 = [f\"model.layers.{i}.mlp.gate_proj\" for i in skip_indices]\n",
    "skip_layers5 = [f\"model.layers.{i}.mlp.up_proj\" for i in skip_indices]\n",
    "skip_layers6 = [f\"model.layers.{i}.mlp.down_proj\" for i in skip_indices]\n",
    "skip_layers = skip_layers0 + skip_layers1 + skip_layers2 + skip_layers3 + skip_layers4 + skip_layers5 + skip_layers6\n",
    "\n",
    "skip_indices =list(range(25, 30))\n",
    "skip_layers3 = [f\"model.layers.{i}.self_attn.o_proj\" for i in skip_indices]\n",
    "skip_layers4 = [f\"model.layers.{i}.mlp.gate_proj\" for i in skip_indices]\n",
    "skip_layers5 = [f\"model.layers.{i}.mlp.up_proj\" for i in skip_indices]\n",
    "skip_layers6 = [f\"model.layers.{i}.mlp.down_proj\" for i in skip_indices]\n",
    "skip_layers_add = skip_layers3 + skip_layers4 + skip_layers5 + skip_layers6\n",
    "\n",
    "IGNORE = [\"embed_tokens\", \"lm_head\"] + skip_layers + skip_layers_add\n",
    "print(f\"제외된 레이어 인덱스: {skip_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963fcbd5",
   "metadata": {},
   "source": [
    "# Model Loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ba78ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] 모델 로드 중...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "print(\"[INFO] 모델/토크나이저 로드 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6ca141",
   "metadata": {},
   "source": [
    "# Dataset Loads & Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a675a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] 캘리브레이션 데이터 로드 중...\")\n",
    "\n",
    "ds = load_dataset(\n",
    "    DATASET_ID,\n",
    "    split=f\"{DATASET_SPLIT}[:{NUM_CALIBRATION_SAMPLES}]\",\n",
    ")\n",
    "\n",
    "def preprocess(example):\n",
    "    return {\n",
    "        \"text\": tokenizer.apply_chat_template(\n",
    "            example[\"conversations\"],\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False)\n",
    "    }\n",
    "\n",
    "ds = ds.map(preprocess)\n",
    "\n",
    "print(\"[INFO] 데이터 전처리 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b30fd6",
   "metadata": {},
   "source": [
    "# GPTQ Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03fee7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"[INFO] GPTQ 시작 (scheme={SCHEME}, samples={NUM_CALIBRATION_SAMPLES}, max_len={MAX_SEQUENCE_LENGTH})...\")\n",
    "\n",
    "recipe = [\n",
    "    GPTQModifier(\n",
    "        scheme=SCHEME,\n",
    "        targets=TARGETS,\n",
    "        ignore=IGNORE,\n",
    "    )\n",
    "]\n",
    "\n",
    "oneshot(\n",
    "    model=model,\n",
    "    dataset=ds,\n",
    "    recipe=recipe,\n",
    "    max_seq_length=MAX_SEQUENCE_LENGTH,\n",
    "    num_calibration_samples=NUM_CALIBRATION_SAMPLES,\n",
    ")\n",
    "\n",
    "print(\"[INFO] GPTQ 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028939d7",
   "metadata": {},
   "source": [
    "# Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac17d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "model.save_pretrained(OUT_DIR, save_compressed=True)\n",
    "tokenizer.save_pretrained(OUT_DIR)\n",
    "\n",
    "print(f\"[INFO] 모델 저장 완료: {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc498b8",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff881e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_name = \"ign\"\n",
    "print(f\"[INFO] {zip_name}.zip 생성 중...\")\n",
    "\n",
    "shutil.make_archive(\n",
    "    base_name=zip_name,\n",
    "    format=\"zip\",\n",
    "    root_dir=\".\",\n",
    "    base_dir=OUT_DIR,\n",
    ")\n",
    "\n",
    "print(f\"[INFO] 생성 완료: {zip_name}.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
