{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18cd4717",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from llmcompressor import oneshot\n",
    "from llmcompressor.modifiers.quantization import GPTQModifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b01058d",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61485104",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"./base_model\"     \n",
    "OUT_DIR  = \"./model\"          \n",
    "\n",
    "DATASET_ID = \"LGAI-EXAONE/MANTA-1M\"\n",
    "DATASET_SPLIT = \"train\"\n",
    "\n",
    "NUM_CALIBRATION_SAMPLES = 1024\n",
    "MAX_SEQUENCE_LENGTH = 256\n",
    "\n",
    "# Quantization\n",
    "SCHEME = \"W4A16\"\n",
    "TARGETS = [\"Linear\"]\n",
    "IGNORE  = [\"embed_tokens\", \"lm_head\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963fcbd5",
   "metadata": {},
   "source": [
    "# Model Loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ba78ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] 모델 로드 중...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "print(\"[INFO] 모델/토크나이저 로드 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6ca141",
   "metadata": {},
   "source": [
    "# Dataset Loads & Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a675a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] 캘리브레이션 데이터 로드 중...\")\n",
    "\n",
    "ds = load_dataset(\n",
    "    DATASET_ID,\n",
    "    split=f\"{DATASET_SPLIT}[:{NUM_CALIBRATION_SAMPLES}]\",\n",
    ")\n",
    "\n",
    "def preprocess(example):\n",
    "    return {\n",
    "        \"text\": tokenizer.apply_chat_template(\n",
    "            example[\"conversations\"],\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False)\n",
    "    }\n",
    "\n",
    "ds = ds.map(preprocess)\n",
    "\n",
    "print(\"[INFO] 데이터 전처리 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b30fd6",
   "metadata": {},
   "source": [
    "# GPTQ Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03fee7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"[INFO] GPTQ 시작 (scheme={SCHEME}, samples={NUM_CALIBRATION_SAMPLES}, max_len={MAX_SEQUENCE_LENGTH})...\")\n",
    "\n",
    "early_range = range(0, 10)\n",
    "mid_range = range(10, 20)\n",
    "late_range = range(20, 30)\n",
    "\n",
    "sub_modules = [\"self_attn.q_proj\", \"self_attn.k_proj\", \"self_attn.v_proj\", \"self_attn.o_proj\", \n",
    "               \"mlp.gate_proj\", \"mlp.up_proj\", \"mlp.down_proj\"]\n",
    "\n",
    "# 최종 타겟 리스트 생성\n",
    "EARLY_TARGETS = [f\"model.layers.{i}.{sub}\" for i in early_range for sub in sub_modules]\n",
    "MID_TARGETS = [f\"model.layers.{i}.{sub}\" for i in mid_range for sub in sub_modules]\n",
    "LATE_TARGETS = [f\"model.layers.{i}.{sub}\" for i in late_range for sub in sub_modules]\n",
    "\n",
    "recipe = [\n",
    "    # 구간 1: 앞부분 (보통 0.01~0.1)\n",
    "    GPTQModifier(\n",
    "        scheme=SCHEME,\n",
    "        targets=EARLY_TARGETS,\n",
    "        ignore=IGNORE, # 사진 속의 그 IGNORE 리스트\n",
    "        dampening_frac=0.1\n",
    "    ),\n",
    "    # 구간 2: 중간 부분 (현재 쓰시는 0.3 수준)\n",
    "    GPTQModifier(\n",
    "        scheme=SCHEME,\n",
    "        targets=MID_TARGETS,\n",
    "        ignore=IGNORE,\n",
    "        dampening_frac=0.3\n",
    "    ),\n",
    "    # 구간 3: 뒷부분 (오차 누적 방지를 위해 0.6 이상으로 조임)\n",
    "    GPTQModifier(\n",
    "        scheme=SCHEME,\n",
    "        targets=LATE_TARGETS,\n",
    "        ignore=IGNORE,\n",
    "        dampening_frac=0.6\n",
    "    )\n",
    "]\n",
    "\n",
    "oneshot(\n",
    "    model=model,\n",
    "    dataset=ds,\n",
    "    recipe=recipe,\n",
    "    max_seq_length=MAX_SEQUENCE_LENGTH,\n",
    "    num_calibration_samples=NUM_CALIBRATION_SAMPLES,\n",
    ")\n",
    "\n",
    "print(\"[INFO] GPTQ 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028939d7",
   "metadata": {},
   "source": [
    "# Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac17d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "model.save_pretrained(OUT_DIR, save_compressed=True)\n",
    "tokenizer.save_pretrained(OUT_DIR)\n",
    "\n",
    "print(f\"[INFO] 모델 저장 완료: {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc498b8",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff881e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_name = \"102425603\"\n",
    "print(f\"[INFO] {zip_name}.zip 생성 중...\")\n",
    "\n",
    "shutil.make_archive(\n",
    "    base_name=zip_name,\n",
    "    format=\"zip\",\n",
    "    root_dir=\".\",\n",
    "    base_dir=OUT_DIR,\n",
    ")\n",
    "\n",
    "print(f\"[INFO] 생성 완료: {zip_name}.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
