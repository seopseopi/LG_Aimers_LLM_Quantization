import os
import torch
import shutil
from pathlib import Path
from datasets import load_dataset
from transformers import AutoModelForCausalLM, AutoTokenizer
from llmcompressor import oneshot
from llmcompressor.modifiers.quantization import GPTQModifier

# ==========================================
# 1. 환경 설정 (Front 9 + 안정적인 Damp 0.1)
# ==========================================
MODEL_ID = "LGAI-EXAONE/EXAONE-4.0-1.2B"
OUT_DIR = "./model"
DATASET_ID = "LGAI-EXAONE/MANTA-1M"
DATASET_SPLIT = "train"

NUM_CALIBRATION_SAMPLES = 4096 
MAX_SEQUENCE_LENGTH = 1024

# ==========================================
# 2. 레이어 무시 전략 (Front-9 유지)
# ==========================================
# 0~8번 레이어까지 전체 FP16 보존 (총 9개)
skip_indices_front = list(range(0, 9)) 
skip_layers_front = []
for i in skip_indices_front:
    skip_layers_front.extend([
        f"model.layers.{i}.self_attn.q_proj",
        f"model.layers.{i}.self_attn.k_proj",
        f"model.layers.{i}.self_attn.v_proj",
        f"model.layers.{i}.self_attn.o_proj",
        f"model.layers.{i}.mlp.gate_proj",
        f"model.layers.{i}.mlp.up_proj",
        f"model.layers.{i}.mlp.down_proj"
    ])

# 9~29번 레이어: down_proj만 FP16 보존
skip_indices_rest = list(range(9, 30))
skip_layers_rest_down = [f"model.layers.{i}.mlp.down_proj" for i in skip_indices_rest]

IGNORE = ["embed_tokens", "lm_head"] + skip_layers_front + skip_layers_rest_down

print(f"[INFO] Front-9 / Damp 0.1 실험 시작 (무시 레이어: {len(IGNORE)}개)")

# ==========================================
# 3. 모델 및 데이터 로딩
# ==========================================
tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_ID,
    torch_dtype=torch.bfloat16,
    device_map="auto"
)

ds = load_dataset(DATASET_ID, split=f"{DATASET_SPLIT}[:{NUM_CALIBRATION_SAMPLES}]")

def preprocess(example):
    return {
        "text": tokenizer.apply_chat_template(
            example["conversations"],
            add_generation_prompt=True,
            tokenize=False)
    }

ds = ds.map(preprocess)

# ==========================================
# 4. GPTQ 양자화 (Damp 0.1로 안정성 확보)
# ==========================================
recipe = [
    GPTQModifier(
        scheme="W4A16",
        targets=["Linear"],
        ignore=IGNORE,
        dampening_frac=0.1 # <--- 안정적인 기본값 0.1 적용
    )
]

print(f"[INFO] Front9_S4096_D0.1 모델 양자화 시작...")

oneshot(
    model=model,
    dataset=ds,
    recipe=recipe,
    max_seq_length=MAX_SEQUENCE_LENGTH,
    num_calibration_samples=NUM_CALIBRATION_SAMPLES,
)

# ==========================================
# 5. 저장 및 압축
# ==========================================
if os.path.exists(OUT_DIR):
    shutil.rmtree(OUT_DIR)
os.makedirs(OUT_DIR, exist_ok=True)

model.save_pretrained(OUT_DIR, save_compressed=True)
tokenizer.save_pretrained(OUT_DIR)

shutil.make_archive(base_name="submit_Front9_S4096_D01", format="zip", root_dir=".", base_dir=OUT_DIR)
print(f"[INFO] 모델 압축 완료: submit_Front9_S4096_D01.zip")
